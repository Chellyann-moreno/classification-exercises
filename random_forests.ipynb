{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df46481",
   "metadata": {},
   "source": [
    "# Work with titanic data to do the following:\n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d360fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import acquire as acq\n",
    "import prepare as prep\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "777d0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=acq.titanic_data()\n",
    "titanic=titanic.fillna(0)\n",
    "titanic.head()\n",
    "titanic=prep.prep_titanic(titanic)\n",
    "train,validate,test=prep.split_data(titanic,'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba399096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.61048689138576"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy=329/(329+205)\n",
    "baseline_accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfa3887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch      fare  \\\n",
       "455           455         1       3    male  29.0      0      0    7.8958   \n",
       "380           380         1       1  female  42.0      0      0  227.5250   \n",
       "492           492         0       1    male  55.0      0      0   30.5000   \n",
       "55             55         1       1    male   0.0      0      0   35.5000   \n",
       "243           243         0       3    male  22.0      0      0    7.1250   \n",
       "\n",
       "     embark_town  sex_male  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "455    Cherbourg         1                      1                       0   \n",
       "380    Cherbourg         0                      1                       0   \n",
       "492  Southampton         1                      0                       0   \n",
       "55   Southampton         1                      0                       0   \n",
       "243  Southampton         1                      0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "455                        0  \n",
       "380                        0  \n",
       "492                        1  \n",
       "55                         1  \n",
       "243                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5a28bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.drop(columns=['survived','passenger_id','sex','embark_town'])\n",
    "y_train= train.survived\n",
    "x_validate=validate.drop(columns=['survived','passenger_id','sex','embark_town'])\n",
    "y_validate= validate.survived\n",
    "x_test=test.drop(columns=['survived','passenger_id','sex','embark_town'])\n",
    "y_test= test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51828e8a",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abaf648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.19101123595506"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=RandomForestClassifier(min_samples_leaf=1,max_depth=10,random_state=123)\n",
    "tree.fit(x_train,y_train)\n",
    "tree.score(x_train,y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b085de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_train\n",
    "y_pred=tree.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891641d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[329,   0],\n",
       "       [ 15, 190]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7aa145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       329\n",
      "           1       1.00      0.93      0.96       205\n",
      "\n",
      "    accuracy                           0.97       534\n",
      "   macro avg       0.98      0.96      0.97       534\n",
      "weighted avg       0.97      0.97      0.97       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58487ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.33707865168539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(x_validate,y_validate)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6aeed71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_predict</th>\n",
       "      <th>1_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_actual</th>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_actual</th>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_predict  1_predict\n",
       "0_actual        329          0\n",
       "1_actual         15        190"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=sorted(y_train.unique())\n",
    "pd.DataFrame(confusion_matrix(y_true,y_pred),\n",
    "            index=[str(label) +'_actual' for label in labels],\n",
    "            columns=[str(label) +'_predict' for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6feddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_true,y_pred)\n",
    "conf.ravel()\n",
    "TN, FP, FN, TP = conf.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e3e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = (TP + TN + FP + FN)\n",
    "\n",
    "accuracy = (TP + TN) / all_\n",
    "\n",
    "TPR = recall = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "TNR = TN / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "precision =  TP / (TP + FP)\n",
    "f1 =  2 * ((precision * recall) / ( precision + recall))\n",
    "\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5976c314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9719101123595506\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.926829268292683\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.0\n",
      "True Negative Rate/Specificity/Selectivity: 1.0\n",
      "False Negative Rate/Miss Rate: 0.07317073170731707\n",
      "\n",
      "Precision/PPV: 1.0\n",
      "F1 Score: 0.9620253164556963\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {TPR}\")\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {FPR}\")\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {TNR}\")\n",
    "print(f\"False Negative Rate/Miss Rate: {FNR}\\n\")\n",
    "print(f\"Precision/PPV: {precision}\")\n",
    "print(f\"F1 Score: {f1}\\n\")\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f2017ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=1, max_depth=10, accuracy_TRAIN=0.97\n",
      "min_samples_leaf=1, max_depth=10, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=1, max_depth=10, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=2, max_depth=9, accuracy_TRAIN=0.92\n",
      "min_samples_leaf=2, max_depth=9, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=2, max_depth=9, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=3, max_depth=8, accuracy_TRAIN=0.91\n",
      "min_samples_leaf=3, max_depth=8, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=3, max_depth=8, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=4, max_depth=7, accuracy_TRAIN=0.89\n",
      "min_samples_leaf=4, max_depth=7, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=4, max_depth=7, accuracy_TEST=0.77\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=5, max_depth=6, accuracy_TRAIN=0.87\n",
      "min_samples_leaf=5, max_depth=6, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=5, max_depth=6, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=6, max_depth=5, accuracy_TRAIN=0.84\n",
      "min_samples_leaf=6, max_depth=5, accuracy_VALIDATE=0.81\n",
      "min_samples_leaf=6, max_depth=5, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=7, max_depth=4, accuracy_TRAIN=0.82\n",
      "min_samples_leaf=7, max_depth=4, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=7, max_depth=4, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=8, max_depth=3, accuracy_TRAIN=0.82\n",
      "min_samples_leaf=8, max_depth=3, accuracy_VALIDATE=0.80\n",
      "min_samples_leaf=8, max_depth=3, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=9, max_depth=2, accuracy_TRAIN=0.82\n",
      "min_samples_leaf=9, max_depth=2, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=9, max_depth=2, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=10, max_depth=1, accuracy_TRAIN=0.77\n",
      "min_samples_leaf=10, max_depth=1, accuracy_VALIDATE=0.77\n",
      "min_samples_leaf=10, max_depth=1, accuracy_TEST=0.77\n"
     ]
    }
   ],
   "source": [
    "score_all=[]\n",
    "\n",
    "min_samples_leaf_values = range(1,12)\n",
    "max_depth_values = range(10,0,-1)\n",
    "\n",
    "# Iterate over the parameter combinations\n",
    "for min_samples_leaf, max_depth in zip(min_samples_leaf_values, max_depth_values):\n",
    "    # Define the Random Forest Classifier with the current parameters\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=min_samples_leaf, max_depth=max_depth,random_state=123)\n",
    "    # Train the model on the training data\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    accuracy_train = clf.score(x_train, y_train)\n",
    "    accuracy_val=clf.score(x_validate, y_validate)\n",
    "    accuracy_test=clf.score(x_test, y_test)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"BASELINE ACCURACY={baseline_accuracy:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_TRAIN={accuracy_train:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_VALIDATE={accuracy_val:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_TEST={accuracy_test:.2f}\")\n",
    "\n",
    "score_all.append([min_samples_leaf,max_depth,accuracy_train,accuracy_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c297f00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773408</td>\n",
       "      <td>0.769663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_leaf  max_depth     train  validate\n",
       "0        10          1  0.773408  0.769663"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_all,columns=['min_leaf','max_depth','train','validate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a287cf",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "4 through 6, there is less overfitting and less accuracy difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4c656",
   "metadata": {},
   "source": [
    "# Telco Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47808276",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco=acq.get_telco_data()\n",
    "telco=prep.prep_telco(telco)\n",
    "train,validate,test=prep.split_data(telco,'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f179cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4225 entries, 5911 to 3586\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   customer_id                            4225 non-null   object \n",
      " 1   gender                                 4225 non-null   object \n",
      " 2   senior_citizen                         4225 non-null   int64  \n",
      " 3   partner                                4225 non-null   object \n",
      " 4   dependents                             4225 non-null   object \n",
      " 5   tenure                                 4225 non-null   int64  \n",
      " 6   phone_service                          4225 non-null   object \n",
      " 7   multiple_lines                         4225 non-null   object \n",
      " 8   online_security                        4225 non-null   object \n",
      " 9   online_backup                          4225 non-null   object \n",
      " 10  device_protection                      4225 non-null   object \n",
      " 11  tech_support                           4225 non-null   object \n",
      " 12  streaming_tv                           4225 non-null   object \n",
      " 13  streaming_movies                       4225 non-null   object \n",
      " 14  paperless_billing                      4225 non-null   object \n",
      " 15  monthly_charges                        4225 non-null   float64\n",
      " 16  total_charges                          4225 non-null   float64\n",
      " 17  churn                                  4225 non-null   object \n",
      " 18  payment_type                           4225 non-null   object \n",
      " 19  internet_service_type                  4225 non-null   object \n",
      " 20  contract_type                          4225 non-null   object \n",
      " 21  gender_encoded                         4225 non-null   int64  \n",
      " 22  partner_encoded                        4225 non-null   int64  \n",
      " 23  dependents_encoded                     4225 non-null   int64  \n",
      " 24  phone_service_encoded                  4225 non-null   int64  \n",
      " 25  paperless_billing_encoded              4225 non-null   int64  \n",
      " 26  churn_encoded                          4225 non-null   int64  \n",
      " 27  multiple_lines_No phone service        4225 non-null   uint8  \n",
      " 28  multiple_lines_Yes                     4225 non-null   uint8  \n",
      " 29  online_security_No internet service    4225 non-null   uint8  \n",
      " 30  online_security_Yes                    4225 non-null   uint8  \n",
      " 31  online_backup_No internet service      4225 non-null   uint8  \n",
      " 32  online_backup_Yes                      4225 non-null   uint8  \n",
      " 33  device_protection_No internet service  4225 non-null   uint8  \n",
      " 34  device_protection_Yes                  4225 non-null   uint8  \n",
      " 35  tech_support_No internet service       4225 non-null   uint8  \n",
      " 36  tech_support_Yes                       4225 non-null   uint8  \n",
      " 37  streaming_tv_No internet service       4225 non-null   uint8  \n",
      " 38  streaming_tv_Yes                       4225 non-null   uint8  \n",
      " 39  streaming_movies_No internet service   4225 non-null   uint8  \n",
      " 40  streaming_movies_Yes                   4225 non-null   uint8  \n",
      " 41  contract_type_One year                 4225 non-null   uint8  \n",
      " 42  contract_type_Two year                 4225 non-null   uint8  \n",
      " 43  internet_service_type_Fiber optic      4225 non-null   uint8  \n",
      " 44  internet_service_type_None             4225 non-null   uint8  \n",
      " 45  payment_type_Credit card (automatic)   4225 non-null   uint8  \n",
      " 46  payment_type_Electronic check          4225 non-null   uint8  \n",
      " 47  payment_type_Mailed check              4225 non-null   uint8  \n",
      "dtypes: float64(2), int64(8), object(17), uint8(21)\n",
      "memory usage: 1010.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e081323",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.iloc[:,-27:].drop(columns=['churn_encoded'])\n",
    "y_train= train.churn\n",
    "x_validate=validate.iloc[:,-27:].drop(columns=['churn_encoded'])\n",
    "y_validate= validate.churn\n",
    "x_test=test.iloc[:,-27:].drop(columns=['churn_encoded'])\n",
    "y_test= test.churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9b2ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3104\n",
       "Yes    1121\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64d98c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.46745562130178"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy=3104/(3104+1121)\n",
    "baseline_accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e0cca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.33727810650888"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=RandomForestClassifier(min_samples_leaf=1,max_depth=10,random_state=123)\n",
    "tree.fit(x_train,y_train)\n",
    "tree.score(x_train,y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0760b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_predict</th>\n",
       "      <th>Yes_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No_actual</th>\n",
       "      <td>2875</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes_actual</th>\n",
       "      <td>475</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            No_predict  Yes_predict\n",
       "No_actual         2875          229\n",
       "Yes_actual         475          646"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=y_train\n",
    "y_pred=tree.predict(x_train)\n",
    "confusion_matrix(y_true,y_pred)\n",
    "labels=sorted(y_train.unique())\n",
    "pd.DataFrame(confusion_matrix(y_true,y_pred),\n",
    "            index=[str(label) +'_actual' for label in labels],\n",
    "            columns=[str(label) +'_predict' for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f39368ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_true,y_pred)\n",
    "conf.ravel()\n",
    "TN, FP, FN, TP = conf.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19f8c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333727810650887\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.576271186440678\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.07377577319587629\n",
      "True Negative Rate/Specificity/Selectivity: 0.9262242268041238\n",
      "False Negative Rate/Miss Rate: 0.423728813559322\n",
      "\n",
      "Precision/PPV: 0.7382857142857143\n",
      "F1 Score: 0.6472945891783568\n",
      "\n",
      "Support (0): 1121\n",
      "Support (1): 3104\n"
     ]
    }
   ],
   "source": [
    "all_ = (TP + TN + FP + FN)\n",
    "\n",
    "accuracy = (TP + TN) / all_\n",
    "\n",
    "TPR = recall = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "TNR = TN / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "precision =  TP / (TP + FP)\n",
    "f1 =  2 * ((precision * recall) / ( precision + recall))\n",
    "\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {TPR}\")\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {FPR}\")\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {TNR}\")\n",
    "print(f\"False Negative Rate/Miss Rate: {FNR}\\n\")\n",
    "print(f\"Precision/PPV: {precision}\")\n",
    "print(f\"F1 Score: {f1}\\n\")\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d81848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=1, max_depth=20, accuracy_TRAIN=0.92\n",
      "min_samples_leaf=1, max_depth=20, accuracy_VALIDATE=0.75\n",
      "min_samples_leaf=1, max_depth=20, accuracy_TEST=0.76\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=2, max_depth=19, accuracy_TRAIN=0.85\n",
      "min_samples_leaf=2, max_depth=19, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=2, max_depth=19, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=3, max_depth=18, accuracy_TRAIN=0.83\n",
      "min_samples_leaf=3, max_depth=18, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=3, max_depth=18, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=4, max_depth=17, accuracy_TRAIN=0.82\n",
      "min_samples_leaf=4, max_depth=17, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=4, max_depth=17, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=5, max_depth=16, accuracy_TRAIN=0.81\n",
      "min_samples_leaf=5, max_depth=16, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=5, max_depth=16, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=6, max_depth=15, accuracy_TRAIN=0.81\n",
      "min_samples_leaf=6, max_depth=15, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=6, max_depth=15, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=7, max_depth=14, accuracy_TRAIN=0.81\n",
      "min_samples_leaf=7, max_depth=14, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=7, max_depth=14, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=8, max_depth=13, accuracy_TRAIN=0.80\n",
      "min_samples_leaf=8, max_depth=13, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=8, max_depth=13, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=9, max_depth=12, accuracy_TRAIN=0.80\n",
      "min_samples_leaf=9, max_depth=12, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=9, max_depth=12, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=10, max_depth=11, accuracy_TRAIN=0.80\n",
      "min_samples_leaf=10, max_depth=11, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=10, max_depth=11, accuracy_TEST=0.78\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=11, max_depth=10, accuracy_TRAIN=0.80\n",
      "min_samples_leaf=11, max_depth=10, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=11, max_depth=10, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=12, max_depth=9, accuracy_TRAIN=0.80\n",
      "min_samples_leaf=12, max_depth=9, accuracy_VALIDATE=0.79\n",
      "min_samples_leaf=12, max_depth=9, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=13, max_depth=8, accuracy_TRAIN=0.79\n",
      "min_samples_leaf=13, max_depth=8, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=13, max_depth=8, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=14, max_depth=7, accuracy_TRAIN=0.79\n",
      "min_samples_leaf=14, max_depth=7, accuracy_VALIDATE=0.78\n",
      "min_samples_leaf=14, max_depth=7, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=15, max_depth=6, accuracy_TRAIN=0.78\n",
      "min_samples_leaf=15, max_depth=6, accuracy_VALIDATE=0.77\n",
      "min_samples_leaf=15, max_depth=6, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=16, max_depth=5, accuracy_TRAIN=0.78\n",
      "min_samples_leaf=16, max_depth=5, accuracy_VALIDATE=0.77\n",
      "min_samples_leaf=16, max_depth=5, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=17, max_depth=4, accuracy_TRAIN=0.77\n",
      "min_samples_leaf=17, max_depth=4, accuracy_VALIDATE=0.77\n",
      "min_samples_leaf=17, max_depth=4, accuracy_TEST=0.79\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=18, max_depth=3, accuracy_TRAIN=0.75\n",
      "min_samples_leaf=18, max_depth=3, accuracy_VALIDATE=0.75\n",
      "min_samples_leaf=18, max_depth=3, accuracy_TEST=0.75\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=19, max_depth=2, accuracy_TRAIN=0.73\n",
      "min_samples_leaf=19, max_depth=2, accuracy_VALIDATE=0.73\n",
      "min_samples_leaf=19, max_depth=2, accuracy_TEST=0.73\n",
      "BASELINE ACCURACY=0.73\n",
      "min_samples_leaf=20, max_depth=1, accuracy_TRAIN=0.73\n",
      "min_samples_leaf=20, max_depth=1, accuracy_VALIDATE=0.73\n",
      "min_samples_leaf=20, max_depth=1, accuracy_TEST=0.73\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf_values = range(1,21)\n",
    "max_depth_values = range(20,0,-1)\n",
    "\n",
    "# Iterate over the parameter combinations\n",
    "for min_samples_leaf, max_depth in zip(min_samples_leaf_values, max_depth_values):\n",
    "    # Define the Random Forest Classifier with the current parameters\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=min_samples_leaf, max_depth=max_depth,)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    accuracy_train = clf.score(x_train, y_train)\n",
    "    accuracy_val=clf.score(x_validate, y_validate)\n",
    "    accuracy_test=clf.score(x_test, y_test)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"BASELINE ACCURACY={baseline_accuracy:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_TRAIN={accuracy_train:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_VALIDATE={accuracy_val:.2f}\")\n",
    "    print(f\"min_samples_leaf={min_samples_leaf}, max_depth={max_depth}, accuracy_TEST={accuracy_test:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
